# Copyright 2012-2020 Akretion France (http://www.akretion.com)
# @author Alexis de Lattre <alexis.delattre@akretion.com>
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).

from odoo import api, fields, models, _
from odoo.exceptions import UserError
from datetime import datetime, date as datelib
import unicodecsv
from tempfile import NamedTemporaryFile
import base64
import logging

logger = logging.getLogger(__name__)
try:
    import openpyxl
except ImportError:
    logger.debug('Cannot import openpyxl')

GENERIC_CSV_DEFAULT_DATE = '%d/%m/%Y'


class AccountMoveImport(models.TransientModel):
    _name = "account.move.import"
    _description = "Import account move from file"
    _check_company_auto = True

    company_id = fields.Many2one(
        'res.company', string='Company',
        required=True, default=lambda self: self.env.company)
    file_to_import = fields.Binary(
        string='File to Import', required=True)
    filename = fields.Char()
    file_format = fields.Selection([
        ('genericxlsx', 'Generic XLSX'),
        ('genericcsv', 'Generic CSV'),
        ('fec_txt', 'FEC (text)'),
        ('nibelis', 'Nibelis (Prisme)'),
        ('quadra', 'Quadra (without analytic)'),
        ('extenso', 'In Extenso'),
        ('cielpaye', 'Ciel Paye'),
        ('payfit', 'Payfit'),
        ('cpt195_txt', 'CPT195 (text)'),
        ], string='File Format', required=True, default='genericxlsx')
    post_move = fields.Boolean(
        string='Post Journal Entry',
        help="If True, the journal entry will be posted after the import.")
    force_journal_id = fields.Many2one(
        'account.journal', string="Force Journal",
        domain="[('company_id', '=', company_id)]", check_company=True,
        help="Journal in which the journal entry will be created, "
        "even if the file indicate another journal.")
    force_move_ref = fields.Char('Force Reference')
    force_move_line_name = fields.Char('Force Label')
    force_move_date = fields.Date('Force Date')
    file_encoding = fields.Selection([
        ('ascii', 'ASCII'),
        ('latin1', 'ISO 8859-15 (alias Latin1)'),
        ('utf-8', 'UTF-8'),
        ], string='File Encoding', default='utf-8')
    # technical fields
    force_move_date_required = fields.Boolean('Force Date Required')
    force_move_line_name_required = fields.Boolean('Force Label Required')
    force_journal_required = fields.Boolean('Force Journal Required')
    advanced_options = fields.Boolean()
    # START GENERIC advanced options
    date_by_move_line = fields.Boolean(
        string='Is date by move line ?',
        help="If enabled, we don't use date to detect the split "
        "of journal entries.")
    skip_null_lines = fields.Boolean(
        string="Skip lines with debit = credit = 0")
    keep_odoo_move_name = fields.Boolean(
        string="Don't Force Journal Entry Name",
        help="If 'move_name' is present in the pivot format and "
        "this option is enabled, it will ignore the value of 'move_name' "
        "and use the sequence generated by Odoo when posting the journal entry.")
    split_move_method = fields.Selection([
        ('balanced', 'Balanced'),
        ('move_name', 'Journal Entry Number'),
        ], default='balanced', required=True,
        help="If you select the method 'Balanced', Odoo will cut the move when a group of lines is balanced with the same journal and date. If you select the method 'Journal Entry Number', Odoo will cut the move using the field 'move_name' of the pivot format (this field is optional, but it will have to be present if you select this method).")
    # START advanced options used in 'genericcsv' import
    # (but could be used by other imports if needed)
    date_format = fields.Char(
        default=GENERIC_CSV_DEFAULT_DATE,
        required=True)
    file_with_header = fields.Boolean(
        string='Has Header Line',
        help="Indicate if the first line is a header line and should be ignored.")

    @api.onchange('file_format')
    def file_format_change(self):
        if self.file_format == 'payfit':
            self.force_move_date_required = True
            self.force_move_line_name_required = True
            self.force_journal_required = True
        else:
            self.force_move_date_required = False
            self.force_move_line_name_required = False
            self.force_journal_required = False

    def button_show_advanced_options(self):
        return self._set_advanced_options(True)

    def button_hide_advanced_options(self):
        return self._set_advanced_options(False)

    def _set_advanced_options(self, advanced_options):
        self.ensure_one()
        self.write({'advanced_options': advanced_options})
        action = self.env["ir.actions.actions"]._for_xml_id(
            "account_move_csv_import.account_move_import_action")
        action['res_id'] = self.id
        return action

    # PIVOT FORMAT
    # [{
    #    'account': '411000',
    #    'analytic': 'ADM',  # analytic account code
    #    'partner': 'R1242',
    #    'name': 'label',  # optional, for account.move.line
    #    'credit': 12.42,
    #    'debit': 0,
    #    'ref': '9804',  # optional
    #    'journal': 'VT',  # journal code
    #    'date': '2017-02-15',  # also accepted in datetime format
    #    'ref: 'X12',
    #    'move_name': 'OD/2022/1242',  # optional, for 'name' of account.move
    #                                  # only used when keep_odoo_move_name = False
    #    'reconcile_ref': 'A1242',  # will be written in import_reconcile
    #                               # and be processed after move line creation
    #    'analytic_tags': 'B12,B13,B14',
    #    'line': 2,  # Line number for error messages.
    #                # Must be the line number including headers
    # },
    #  2nd line...
    #  3rd line...
    # ]

    def file2pivot(self, fileobj, file_bytes):
        file_format = self.file_format
        if file_format == 'nibelis':
            return self.nibelis2pivot(fileobj)
        elif file_format == 'genericcsv':
            return self.genericcsv2pivot(fileobj)
        elif file_format == 'genericxlsx':
            return self.genericxlsx2pivot(fileobj)
        elif file_format == 'quadra':
            return self.quadra2pivot(file_bytes)
        elif file_format == 'extenso':
            return self.extenso2pivot(fileobj)
        elif file_format == 'payfit':
            return self.payfit2pivot(fileobj)
        elif file_format == 'cielpaye':
            return self.cielpaye2pivot(fileobj)
        elif file_format == 'fec_txt':
            return self.fectxt2pivot(fileobj)
        elif file_format == 'cpt195_txt':
            return self.cpt195txt2pivot(fileobj)
        else:
            raise UserError(_("You must select a file format."))

    def run_import(self):
        self.ensure_one()
        fileobj = NamedTemporaryFile('wb+', prefix='odoo-move_import-', suffix='.xlsx')
        file_bytes = base64.b64decode(self.file_to_import)
        fileobj.write(file_bytes)
        fileobj.seek(0)  # We must start reading from the beginning !
        pivot = self.file2pivot(fileobj, file_bytes)
        fileobj.close()
        logger.debug('pivot before update: %s', pivot)
        self.clean_strip_pivot(pivot)
        self.update_pivot(pivot)
        moves = self.create_moves_from_pivot(pivot, post=self.post_move)
        self.reconcile_move_lines(moves)
        action = self.env["ir.actions.actions"]._for_xml_id(
            "account.action_move_journal_line")
        if len(moves) == 1:
            action.update({
                'view_mode': 'form,tree',
                'res_id': moves[0].id,
                'view_id': False,
                'views': False,
                })
        else:
            action.update({
                'view_mode': 'tree,form',
                'domain': [('id', 'in', moves.ids)],
                })
        return action

    def clean_strip_pivot(self, pivot):
        for l in pivot:
            for key, value in l.items():
                if value:
                    if isinstance(value, str):
                        l[key] = value.strip() or False
                else:
                    l[key] = False

    def update_pivot(self, pivot):
        force_move_date = self.force_move_date
        force_move_ref = self.force_move_ref
        force_move_line_name = self.force_move_line_name
        force_journal_code =\
            self.force_journal_id and self.force_journal_id.code or False
        for l in pivot:
            if force_move_date:
                l['date'] = force_move_date
            if force_move_line_name:
                l['name'] = force_move_line_name
            if force_move_ref:
                l['ref'] = force_move_ref
            if force_journal_code:
                l['journal'] = force_journal_code
            if not l['credit']:
                l['credit'] = 0.0
            if not l['debit']:
                l['debit'] = 0.0

    def extenso2pivot(self, fileobj):
        fieldnames = [
            'journal', 'date', False, 'account', False, False, False, False,
            'debit', 'credit']
        reader = unicodecsv.DictReader(
            fileobj,
            fieldnames=fieldnames,
            delimiter='\t',
            quoting=unicodecsv.QUOTE_MINIMAL,
            encoding='utf-8')
        res = []
        i = 0
        for l in reader:
            i += 1
            l['credit'] = l['credit'] or '0'
            l['debit'] = l['debit'] or '0'
            vals = {
                'journal': l['journal'],
                'account': l['account'],
                'credit': float(l['credit'].replace(',', '.')),
                'debit': float(l['debit'].replace(',', '.')),
                'date': datetime.strptime(l['date'], '%d%m%Y'),
                'line': i,
            }
            res.append(vals)
        return res

    def cielpaye2pivot(self, fileobj):
        fieldnames = [
            False, 'journal', 'date', 'account', False, 'amount', 'sign',
            False, 'name', False]
        reader = unicodecsv.DictReader(
            fileobj,
            fieldnames=fieldnames,
            delimiter='\t',
            quoting=unicodecsv.QUOTE_MINIMAL,
            encoding='utf-8')
        res = []
        i = 0
        for l in reader:
            i += 1
            # skip non-move lines
            if l.get('date') and l.get('name') and l.get('amount'):
                amount = float(l['amount'].replace(',', '.'))
                vals = {
                    'journal': l['journal'],
                    'account': l['account'],
                    'credit': l['sign'] == 'C' and amount or 0,
                    'debit': l['sign'] == 'D' and amount or 0,
                    'date': datetime.strptime(l['date'], '%d/%m/%Y'),
                    'name': l['name'],
                    'line': i,
                }
                res.append(vals)
        return res

    def fectxt2pivot(self, fileobj):
        fieldnames = [
            'journal',        # JournalCode
            False,            # JournalLib
            False,            # EcritureNum
            'date',           # EcritureDate
            'account',        # CompteNum
            False,            # CompteLib
            'partner_ref',    # CompAuxNum
            False,            # CompAuxLib
            'ref',            # PieceRef
            False,            # PieceDate
            'name',           # EcritureLib
            'debit',          # Debit
            'credit',         # Credit
            'reconcile_ref',  # EcritureLet
            False,            # DateLet
            False,            # ValidDate
            False,            # Montantdevise
            False,            # Idevise
            ]
        first_line = fileobj.readline().decode()
        dialect = unicodecsv.Sniffer().sniff(first_line, delimiters="|\t")
        fileobj.seek(0)
        reader = unicodecsv.DictReader(
            fileobj,
            fieldnames=fieldnames,
            delimiter=dialect.delimiter,
            encoding=self.file_encoding)
        res = []
        i = 0
        for l in reader:
            i += 1
            # Skip header line
            if i == 1:
                continue
            l['credit'] = l['credit'] or '0'
            l['debit'] = l['debit'] or '0'
            vals = {
                'journal': l['journal'],
                'account': l['account'],
                'partner': l['partner_ref'],
                'credit': float(l['credit'].replace(',', '.')),
                'debit': float(l['debit'].replace(',', '.')),
                'date': datetime.strptime(l['date'], '%Y%m%d'),
                'name': l['name'],
                'ref': l['ref'],
                'reconcile_ref': l['reconcile_ref'],
                'line': i,
            }
            res.append(vals)
        return res

    def genericcsv2pivot(self, fileobj):
        # Prisme
        fieldnames = [
            'date', 'journal', 'account', 'partner',
            'analytic', 'name', 'debit', 'credit',
            'ref', 'reconcile_ref'
            ]
        first_line = fileobj.readline().decode()
        dialect = unicodecsv.Sniffer().sniff(first_line)
        fileobj.seek(0)
        reader = unicodecsv.DictReader(
            fileobj,
            fieldnames=fieldnames,
            delimiter=dialect.delimiter,
            quotechar='"',
            quoting=unicodecsv.QUOTE_MINIMAL,
            encoding='utf-8-sig')
        # I use utf-8-sig instead of utf-8 to transparently handle BOM
        # https://en.wikipedia.org/wiki/Byte_order_mark
        res = []
        i = 0
        for l in reader:
            i += 1
            if i == 1 and self.file_with_header:
                continue
            date_str = l['date']
            try:
                date = datetime.strptime(date_str, self.date_format)
            except Exception:
                raise UserError(_(
                    "Date parsing error: '%s' in line %s does not match "
                    "date format '%s'.") % (date_str, i, self.date_format))

            vals = {
                'journal': l['journal'],
                'account': l['account'],
                'credit': float(l['credit'].replace(',', '.') or 0),
                'debit': float(l['debit'].replace(',', '.') or 0),
                'date': date,
                'name': l['name'],
                'ref': l.get('ref', ''),
                'reconcile_ref': l.get('reconcile_ref', ''),
                'line': i,
                }
            if l['analytic']:
                vals['analytic'] = l['analytic']
            if l['partner']:
                vals['partner'] = l['partner']
            res.append(vals)
        return res

    def genericxlsx2pivot(self, fileobj):
        wb = openpyxl.load_workbook(fileobj.name, read_only=True)
        sh = wb.active
        res = []
        i = 0
        for row in sh.rows:
            i += 1
            if i == 1 and self.file_with_header:
                continue
            if len(row) < 8:
                continue
            if not [item for item in row if item.value]:
                # skip empty line
                continue
            vals = {
                'date': row[0].value,
                'journal': row[1].value,
                'account': str(row[2].value),
                'partner': row[3].value or False,
                'analytic': row[4].value or False,
                'name': row[5].value,
                'debit': row[6].value,
                'credit': row[7].value,
                'ref': len(row) > 8 and row[8].value or '',
                'reconcile_ref': len(row) > 9 and row[9].value or '',
                'analytic_tags': len(row) > 10 and row[10].value or '',
                'line': i,
                }
            res.append(vals)
        return res

    def nibelis2pivot(self, fileobj):
        fieldnames = [
            'trasha', 'trashb', 'journal', 'trashd', 'trashe',
            'trashf', 'trashg', 'date', 'trashi', 'trashj', 'trashk',
            'trashl', 'trashm', 'trashn', 'account', 'trashp',
            'trashq', 'amount', 'trashs', 'sign', 'trashu',
            'trashv', 'name',
            'trashx', 'trashy', 'trashz', 'trashaa', 'trashab',
            'trashac', 'trashad', 'trashae', 'analytic']
        reader = unicodecsv.DictReader(
            fileobj,
            fieldnames=fieldnames,
            delimiter=';',
            quoting=unicodecsv.QUOTE_MINIMAL,
            encoding='latin1')
        res = []
        i = 0
        for l in reader:
            i += 1
            if i == 1:
                continue
            amount = float(l['amount'].replace(',', '.'))
            credit = l['sign'] == 'C' and amount or False
            debit = l['sign'] == 'D' and amount or False
            vals = {
                'journal': l['journal'],
                'account': l['account'],
                'credit': credit,
                'debit': debit,
                'date': datetime.strptime(l['date'], '%y%m%d'),
                'name': l['name'],
                'line': i,
            }
            if l.get('analytic'):
                vals['analytic'] = l['analytic']
            res.append(vals)
        return res

    def quadra2pivot(self, file_bytes):
        i = 0
        res = []
        file_str = file_bytes.decode(self.file_encoding)
        for l in file_str.split('\n'):
            i += 1
            if len(l) < 54:
                continue
            if l[0] == 'M' and l[41] in ('C', 'D'):
                amount_cents = int(l[42:55])
                amount = amount_cents / 100.0
                vals = {
                    'journal': l[9:11],
                    'account': l[1:9],
                    'credit': l[41] == 'C' and amount or False,
                    'debit': l[41] == 'D' and amount or False,
                    'date': datetime.strptime(l[14:20], '%d%m%y'),
                    'name': l[21:41],
                    'line': i,
                }
                res.append(vals)
        return res

    def payfit2pivot(self, fileobj):
        # Columns in Payfit exported CSV :
        # JournalCode
        # JournalLib
        # EcritureDate
        # CompteNum
        # CompteLib
        # Debit
        # Credit
        # AxeLib
        # AxeReference
        reader = unicodecsv.DictReader(fileobj, delimiter=";", encoding="utf-8")
        i = 0
        res = []
        for l in reader:
            i += 1
            vals = {
                "journal": l.get("JournalCode", ""),
                "account": l["CompteNum"],
                "name": l["CompteLib"],
                "credit": float(l["Credit"] or 0.0),
                "debit": float(l["Debit"] or 0.0),
                "analytic": l.get("AxeReference", ""),
                "date": datetime.strptime(l["EcritureDate"], "%d/%m/%Y"),
                "line": i,
            }
            res.append(vals)
        return res

    def cpt195txt2pivot(self, fileobj):
        res = []
        i = 0
        file_content = base64.decodebytes(self.file_to_import)
        file_content = file_content.decode("latin1")
        file_lines = file_content[:-4].split("\r\n")
        for line in file_lines:
            i += 1
            # Skip empty line
            if not line:
                continue
            # Skip line that is not a detail of the account
            if line[21] != 'D':
                continue
            vals = {
                'journal': line[16:19],
                'account': line[24:36],
                "analytic": line[36:43] != "9999999" and line[36:43],
                'date': datelib(
                    year=int(line[158:160] + line[14:16]),
                    month=int(line[12:14]),
                    day=int(line[22:24]),
                    ),
                'name': line[80:100],
                'ref': line[140:143],
                'line': i,
            }
            credit = int(line[67:80]) / 100.
            debit = int(line[54:67]) / 100.
            if credit and debit:
                vals.update({"credit": credit, "debit": 0})
                res.append(vals)
                vals2 = vals.copy()
                vals2.update({"credit": 0, "debit": debit})
                res.append(vals2)
            else:
                vals.update({"credit": credit, "debit": debit})
                res.append(vals)
        return res

    def _prepare_partner_speeddict(self, company_id):
        speeddict = {}
        partner_sr = self.env['res.partner'].search_read(
            [
                '|',
                ('company_id', '=', company_id),
                ('company_id', '=', False),
                ('ref', '!=', False),
                ('parent_id', '=', False),
            ],
            ['ref'])
        for l in partner_sr:
            speeddict[l['ref'].upper()] = l['id']
        return speeddict

    def _prepare_speeddict(self, company_id):
        speeddict = {
            "partner": self._prepare_partner_speeddict(company_id),
            "journal": {},
            "account": {},
            "analytic": {},
            "analytic_tag": {},
            }
        acc_sr = self.env['account.account'].search_read([
            ('company_id', '=', company_id),
            ('deprecated', '=', False)], ['code'])
        for l in acc_sr:
            speeddict['account'][l['code'].upper()] = l['id']
        aacc_sr = self.env['account.analytic.account'].search_read(
            [('company_id', '=', company_id), ('code', '!=', False)],
            ['code'])
        for l in aacc_sr:
            speeddict['analytic'][l['code'].upper()] = l['id']
        # By default, read access on account.analytic.tag
        # is only granted if the user is in the group 'Analytic Tags'
        if self.env.user.has_group('analytic.group_analytic_tags'):
            anatag_sr = self.env['account.analytic.tag'].search_read(
                ['|', ('company_id', '=', False), ('company_id', '=', company_id)],
                ['name'])
            for tag in anatag_sr:
                speeddict['analytic_tag'][tag['name'].upper()] = tag['id']
        else:
            # Designed to trigger an error during import if analytic tags
            # are used in the input file
            speeddict["analytic_tag_no_access"] = True
        journal_sr = self.env['account.journal'].search_read([
            ('company_id', '=', company_id)], ['code'])
        for l in journal_sr:
            speeddict['journal'][l['code'].upper()] = l['id']
        return speeddict

    def create_moves_from_pivot(self, pivot, post=False):
        logger.debug('Final pivot: %s', pivot)
        amo = self.env['account.move']
        company_id = self.company_id.id
        speeddict = self._prepare_speeddict(company_id)
        key2label = {
            'journal': _('journal codes'),
            'account': _('account codes'),
            'partner': _('partner reference'),
            'analytic': _('analytic codes'),
            'analytic_tag': _('analytic tags'),
            }
        errors = {'other': []}
        for key in key2label.keys():
            errors[key] = {}
        # MATCHES + CHECKS
        for l in pivot:
            assert l.get('line') and isinstance(l.get('line'), int),\
                'missing line number'
            if l['account'] in speeddict['account']:
                l['account_id'] = speeddict['account'][l['account']]
            if not l.get('account_id'):
                # Match when import = 61100000 and Odoo has 611000
                acc_code_tmp = l['account']
                while acc_code_tmp and acc_code_tmp[-1] == '0':
                    acc_code_tmp = acc_code_tmp[:-1]
                    if acc_code_tmp and acc_code_tmp in speeddict['account']:
                        l['account_id'] = speeddict['account'][acc_code_tmp]
                        break
            if not l.get('account_id'):
                # Match when import = 611000 and Odoo has 611000XX
                for code, account_id in speeddict['account'].items():
                    if code.startswith(l['account']):
                        logger.warning(
                            "Approximate match: import account %s has been matched "
                            "with Odoo account %s" % (l['account'], code))
                        l['account_id'] = account_id
                        break
            if not l.get('account_id'):
                errors['account'].setdefault(l['account'], []).append(l['line'])
            if l.get('partner'):
                if l['partner'] in speeddict['partner']:
                    l['partner_id'] = speeddict['partner'][l['partner']]
                else:
                    errors['partner'].setdefault(l['partner'], []).append(l['line'])
            if l.get('analytic'):
                if l['analytic'] in speeddict['analytic']:
                    l['analytic_account_id'] = speeddict['analytic'][l['analytic']]
                else:
                    errors['analytic'].setdefault(l['analytic'], []).append(l['line'])
            if l.get('analytic_tags'):
                if speeddict.get("analytic_tag_no_access"):
                    raise UserError(_(
                        "You are trying to import analytic tag(s) (line %d), "
                        "but you are not part of the group "
                        "'Analytic Accounting Tags'.") % l['line'])
                # split by coma and strip
                l['analytic_tag_ids'] = []
                for rawtag in l['analytic_tags'].split(','):
                    tag = rawtag and rawtag.strip() or False
                    if tag:
                        if tag in speeddict['analytic_tag']:
                            l['analytic_tag_ids'].append(speeddict['analytic_tag'][tag])
                        else:
                            errors['analytic_tag'].setdefault(tag, []).append(l['line'])

            if l['journal'] in speeddict['journal']:
                l['journal_id'] = speeddict['journal'][l['journal']]
            else:
                errors['journal'].setdefault(l['journal'], []).append(l['line'])
            if not l.get('date'):
                errors['other'].append(_(
                    'Line %d: missing date.') % l['line'])
            else:
                if not isinstance(l.get('date'), datelib):
                    try:
                        l['date'] = datetime.strptime(l['date'], '%Y-%m-%d')
                    except Exception:
                        errors['other'].append(_(
                            'Line %d: bad date format %s') % (l['line'], l['date']))
            if not isinstance(l.get('credit'), (float, int)):
                errors['other'].append(_(
                    'Line %d: bad value for credit (%s).')
                    % (l['line'], l['credit']))
            if not isinstance(l.get('debit'), (float, int)):
                errors['other'].append(_(
                    'Line %d: bad value for debit (%s).')
                    % (l['line'], l['debit']))
            # test that they don't have both a value
        # LIST OF ERRORS
        msg = ''
        for key, label in key2label.items():
            if errors[key]:
                msg += _("List of %s that don't exist in Odoo:\n%s\n\n") % (
                    label,
                    '\n'.join([
                        '- %s : line(s) %s' % (code, ', '.join([str(i) for i in lines]))
                        for (code, lines) in errors[key].items()]))
        if errors['other']:
            msg += _('List of misc errors:\n%s') % (
                '\n'.join(['- %s' % e for e in errors['other']]))
        if msg:
            raise UserError(msg)
        # EXTRACT MOVES
        skip_null_lines = self.skip_null_lines
        split_move_method = self.split_move_method
        moves = []
        cur_journal_id = False
        cur_move_name = False
        cur_date = False
        cur_balance = 0.0
        comp_cur = self.company_id.currency_id
        seq = self.env['ir.sequence'].next_by_code('account.move.import')
        cur_move = {}
        for l in pivot:
            if (
                    skip_null_lines and
                    comp_cur.is_zero(l['credit']) and
                    comp_cur.is_zero(l['debit'])):
                logger.info('Skip line %d which has debit=credit=0', l['line'])
                continue
            move_name = l.get('move_name')
            if split_move_method == 'move_name':
                if not move_name:
                    errors['other'].append(_(
                        'Line %d: missing journal entry number.') % l['line'])
                same_move = [cur_move_name == move_name]
            elif split_move_method == 'balanced':
                same_move = [
                    cur_journal_id == l['journal_id'],
                    not comp_cur.is_zero(cur_balance)]
                if not self.date_by_move_line:
                    same_move.append(cur_date == l['date'])
            else:
                raise UserError(_("Wrong Move Split Method."))
            if all(same_move):  # append to current move
                cur_move['line_ids'].append((0, 0, self._prepare_move_line(l, seq)))
            else:  # new move
                if cur_move:
                    if len(cur_move['line_ids']) <= 1:
                        raise UserError(_(
                            "Journal entry on line %d only has 1 line.\n\n"
                            "Debug data: %s") % (l['line'], cur_move['line_ids']))
                    moves.append(cur_move)
                cur_move = self._prepare_move(l)
                cur_move['line_ids'] = [(0, 0, self._prepare_move_line(l, seq))]
                cur_date = l['date']
                cur_move_name = move_name
                cur_journal_id = l['journal_id']
                cur_balance = 0.0
            cur_balance += l['credit'] - l['debit']
        if cur_move:
            moves.append(cur_move)
        if not comp_cur.is_zero(cur_balance):
            raise UserError(_(
                "The journal entry that ends on the last line is not "
                "balanced (balance is %s).") % cur_balance)
        rmoves = self.env['account.move']
        for move in moves:
            rmoves += amo.create(move)
        logger.info(
            'Account moves IDs %s created via file import' % rmoves.ids)
        if post:
            rmoves.action_post()
        return rmoves

    def _prepare_move(self, pivot_line):
        vals = {
            'journal_id': pivot_line['journal_id'],
            'ref': pivot_line.get('ref'),
            'date': pivot_line['date'],
            }
        if pivot_line.get('move_name') and not self.keep_odoo_move_name:
            vals['name'] = pivot_line['move_name']
        return vals

    def _prepare_move_line(self, pivot_line, sequence):
        ana_tag_ids = pivot_line.get('analytic_tag_ids')
        vals = {
            'credit': pivot_line['credit'],
            'debit': pivot_line['debit'],
            'name': pivot_line['name'],
            'partner_id': pivot_line.get('partner_id'),
            'account_id': pivot_line['account_id'],
            'analytic_account_id': pivot_line.get('analytic_account_id'),
            'analytic_tag_ids': ana_tag_ids and [(6, 0, ana_tag_ids)] or False,
            'import_reconcile': pivot_line.get('reconcile_ref'),
            'import_external_id': '%s-%s' % (sequence, pivot_line.get('line')),
            }
        return vals

    def reconcile_move_lines(self, moves):
        comp_cur = self.company_id.currency_id
        logger.info('Start to reconcile imported moves')
        lines = self.env['account.move.line'].search([
            ('move_id', 'in', moves.ids),
            ('import_reconcile', '!=', False),
            ])
        torec = {}  # key = reconcile mark, value = movelines_recordset
        for line in lines:
            if line.import_reconcile in torec:
                torec[line.import_reconcile] |= line
            else:
                torec[line.import_reconcile] = line
        for rec_ref, lines_to_rec in torec.items():
            if len(lines_to_rec) < 2:
                logger.warning(
                    "Skip reconcile of ref '%s' because "
                    "this ref is only on 1 move line", rec_ref)
                continue
            total = 0.0
            accounts = {}
            partners = {}
            for line in lines_to_rec:
                total += line.credit
                total -= line.debit
                accounts[line.account_id] = True
                partners[line.partner_id.id or False] = True
            if not comp_cur.is_zero(total):
                logger.warning(
                    "Skip reconcile of ref '%s' because the lines with "
                    "this ref are not balanced (%s)", rec_ref, total)
                continue
            if len(accounts) > 1:
                logger.warning(
                    "Skip reconcile of ref '%s' because the lines with "
                    "this ref have different accounts (%s)",
                    rec_ref, ', '.join([acc.code for acc in accounts.keys()]))
                continue
            if not list(accounts)[0].reconcile:
                logger.warning(
                    "Skip reconcile of ref '%s' because the account '%s' "
                    "is not configured with 'Allow Reconciliation'",
                    rec_ref, list(accounts)[0].display_name)
                continue
            if len(partners) > 1:
                logger.warning(
                    "Skip reconcile of ref '%s' because the lines with "
                    "this ref have different partners (IDs %s)",
                    rec_ref, ', '.join(partners.keys()))
                continue
            lines_to_rec.reconcile()
        logger.info('Reconcile imported moves finished')
